<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kristinagagalova.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kristinagagalova.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-29T12:01:36+00:00</updated><id>https://kristinagagalova.github.io/feed.xml</id><title type="html">GigaThoughts - by Dr. Kristina K. Gagalova</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">If you‚Äôre not using pipelines, you‚Äôre not doing it right.</title><link href="https://kristinagagalova.github.io/blog/2025/workflows/" rel="alternate" type="text/html" title="If you‚Äôre not using pipelines, you‚Äôre not doing it right."/><published>2025-06-28T11:00:00+00:00</published><updated>2025-06-28T11:00:00+00:00</updated><id>https://kristinagagalova.github.io/blog/2025/workflows</id><content type="html" xml:base="https://kristinagagalova.github.io/blog/2025/workflows/"><![CDATA[<h2 id="at-the-beginning">At the beginning‚Ä¶</h2> <blockquote> <p>[!WARNING] If you‚Äôre not using pipelines, you‚Äôre not doing it right.</p> </blockquote> <p>I still remember the moment it all shifted, the moment I realized I needed more than just a tangle of scripts to make sense of my work.</p> <p>It was 2016. My folders were a graveyard of .sh files ‚Äî some reused, some renamed, some‚Ä¶ unrecognizable. I had directories each holding outputs from hours of computation. No logs. No checkpoints. No version control. Just layers of pure chaos. <br/> At the time, I was collaborating with Leiden University Medical Centre (LUMC). We were building a genome analysis pipeline together, and for the first time, I wasn‚Äôt working alone. Suddenly, my improvised workflows weren‚Äôt enough. I couldn‚Äôt hand over a pile of scripts and hope others would follow the logic I barely remembered. <br/> So we did something different.</p> <p>We designed a real workflow. It had structure. It had checkpoints. It had version control. And more importantly, it could be reused, shared, and executed reliably across systems and users. <br/> That collaboration was my turning point. I stopped thinking of computational analysis as a loose collection of steps. I began to see it as something engineered ‚Äî something built, not just hacked together. It was the beginning of a shift in how I approached bioinformatics altogether.</p> <h2 id="-bulb-my-first-workflow-in-gnu-make">üß∞ :bulb: My first workflow in GNU Make</h2> <p>My first workflows were developed in GNU Make, which was widely employed but not officially for workflows. Make was created in 1976 as part of the Unix ecosystem. Its purpose was simple: to automate the building of programs by describing how files depend on one another and what commands are needed to update them.</p> <p>The GNU version, GNU Make, is part of the GNU Project, and remains widely used in open-source development today. It‚Äôs what you run when you type make in countless software packages to compile code, install dependencies, or manage complex build systems. But its power extends far beyond software compilation. In essence, Make is a rule-based execution engine: You define targets, their dependencies, and the commands to produce them. Then, make it automatically run only what‚Äôs needed and skip everything that‚Äôs already up to date. This makes it surprisingly useful in bioinformatics, especially for reproducible data processing pipelines, managing intermediate files and dependencies, and automating multi-step analyses across projects</p> <p>It‚Äôs minimalist, elegant, and brutally efficient, the grandfather of all scientific workflow tools.</p> <h2 id="snake-enter-snakemake-workflows-with-python-structure">:snake: Enter Snakemake: workflows with Python structure</h2> <p>Soon after, I met Snakemake, the workflow manager that changed everything for me. For those unfamiliar: Snakemake is a workflow system modelled on Makefiles but powered by Python, designed by Johannes K√∂ster. It lets you define your analysis as a set of rules, with clear input/output relationships, and automatically determines what needs to be (re)run.</p> <p>Snakemake was able to define rules that map input files to output files and use wildcards to handle variable filenames automatically, similar to Make, but it had more than this. It was also able to specify resources (e.g., threads, memory, runtime) per rule and integrate cluster schedulers. Furthermore enables the user to run containers or Conda environments per rule for reproducibility which was the real gamechanger.</p> <p>My appreciation for Snakemake deepened not just in academia, but when I transitioned to a project in the private sector. I was tasked with building and maintaining a workflow to process genome assemblies for multiple samples per week. Each dataset needed to be handled with precision and complete reproducibility. This is where Snakemake truly proved itself.</p> <p>I didn‚Äôt just learn Snakemake as a tool. I learned to think in pipelines, spending a considerable amount of hours learning efficient pipeline structures. Additionally, I began to understand the beauty of abstraction, the value of modularity, and the quiet power of a system that runs without needing to be babysat. I learned to anticipate bottlenecks, handle exceptions, and build in documentation as part of the process, not as an afterthought. That experience taught me to appreciate well-crafted workflows, working together with collaborators on the project, not just as a means to an end, but as a scientific and engineering discipline in their own right. Good pipelines aren‚Äôt just functional. They‚Äôre elegant. They scale, they document thinking, and they make processes more reliable.</p> <p>Snakemake gave me my first real taste of that elegance ‚Äî and it set the bar for everything that came next. The pipeline is still very popular today, widely applicable to many workflows.</p> <h2 id="-scaling-up-with-nextflow">üîÑ Scaling up with Nextflow</h2> <p>As my projects grew in complexity, spanning hundreds of genomes and datasets across teams at the Centre for Crop and Disease Management, I eventually reached the limits of what Snakemake. While it had been the perfect companion for flexible, readable workflows, I needed something built from the ground up for large-scale, distributed computing. That‚Äôs when I turned to Nextflow. That‚Äôs when I turned to Nextflow.</p> <p>Nextflow is a data-driven workflow manager developed by Paolo Di Tommaso. It was designed specifically for scalable, reproducible workflows in bioinformatics, and it has become one of the most powerful and widely adopted tools for HPC and cloud-based analysis. Unlike other workflow engines, Nextflow combines a scripting language (based on Groovy) with native support for parallel execution across local, HPC, and cloud environments. It allows to use of containers (Docker, Singularity, Podman) and Conda environments. The pipelines have full pipeline portability and sharing via GitHub. And most importantly, I could do it all without changing my core logic. The workflow was infrastructure-agnostic. I could develop locally, run on HPC, or deploy to AWS with minimal reconfiguration.</p> <h2 id="loudspeaker-pushpin-summary--final-thoughts">:loudspeaker: :pushpin: Summary &amp; Final Thoughts</h2> <p>What began as a way to clean up my folders became something much deeper: An adoption of engineering science, where code isn‚Äôt just functional but elegant and shareable. If you‚Äôre still running analyses manually, copying files, rewriting scripts, and tracking steps by memory, it‚Äôs time to stop. Because good science deserves clarity, structure, and reproducibility, all of which can be achieved through pipelines.</p> <blockquote> <p>[!TIP] If you‚Äôre not using pipelines, you‚Äôre not doing it right.</p> </blockquote> <h2 id="-further-reading--useful-links">üîó Further Reading &amp; Useful Links</h2> <ul> <li> <p>üß∞ <strong>GNU Make</strong><br/> <a href="https://www.gnu.org/software/make/">https://www.gnu.org/software/make/</a><br/> Official documentation for GNU Make ‚Äî a foundational tool for automation and dependency management.</p> </li> <li> <p>üêç <strong>Snakemake</strong><br/> <a href="https://snakemake.readthedocs.io">https://snakemake.readthedocs.io</a><br/> Comprehensive documentation, tutorials, and examples for writing reproducible workflows with Snakemake.</p> </li> <li> <p>üîÑ <strong>Nextflow</strong><br/> <a href="https://www.nextflow.io">https://www.nextflow.io</a><br/> Main Nextflow website with guides, documentation, and getting started materials.</p> </li> </ul>]]></content><author><name></name></author><category term="personal-perspective"/><category term="workflows"/><category term="nextflow"/><summary type="html"><![CDATA[workflows - from scripts to scale]]></summary></entry><entry><title type="html">Migrating to 25.04 ‚Äî Nextflow documentation</title><link href="https://kristinagagalova.github.io/blog/2025/migrating-to-2504-nextflow-documentation/" rel="alternate" type="text/html" title="Migrating to 25.04 ‚Äî Nextflow documentation"/><published>2025-05-08T00:00:00+00:00</published><updated>2025-05-08T00:00:00+00:00</updated><id>https://kristinagagalova.github.io/blog/2025/migrating-to-2504--nextflow-documentation</id><content type="html" xml:base="https://kristinagagalova.github.io/blog/2025/migrating-to-2504-nextflow-documentation/"><![CDATA[<p>Get startedRunning pipelinesDeveloping pipelinesSoftware dependenciesCompute &amp; storageLanguage ReferenceRuntime ReferenceUpdatesContributingGuidesNextflow 25.04 was released on May 8, 2025.The strict syntax is a strict parser for Nextflow DSL2 that implements the Nextflow language specification. Originally introduced by the Nextflow language server alongside Nextflow 24.10, the strict syntax is now available in the Nextflow CLI.The strict syntax is disabled by default. It can be enabled by setting the environment variable NXF_SYNTAX_PARSER=v2. See Preparing for strict syntax for details.The nextflow lint command checks Nextflow scripts and config files for errors using the strict syntax. It can also format Nextflow files using the same formatter as the Nextflow language server. See lint for details.The third preview of workflow outputs introduces the following breaking changes from the previous version:The publish: section can only be specified in the entry workflow.Workflow outputs in the publish: section are assigned instead of using the¬†¬ª operator. Output names must be valid identifiers.By default, output files are published to the base output directory, rather than a subdirectory corresponding to the output name.The syntax for dynamic publish paths has changed. Instead of defining a closure that returns a closure with the path directive, the outer closure should use the¬†¬ª operator to publish individual files. See Publishing files for details.The mapper index directive has been removed. Use a map operator in the workflwo body instead.See Workflow outputs to learn more about the workflow output definition.Topic channels, introduced in Nextflow 24.04 as a preview feature, have been brought out of preview, which means that they can be used without the nextflow.preview.topic feature flag.This release introduces built-in provenance tracking, also known as data lineage. When lineage.enabled is set to true in your configuration, Nextflow will record every workflow run, task execution, output file, and the links between them.You can explore this lineage from the command line using the lineage command. Additionally, you can refer to files in the lineage store from a Nextflow script using the lid:// path prefix as well as the fromLineage channel factory.See the Data lineage guide to get started.Previously, the nextflow inspect command included all processes that were invoked in a preview run. Now, the inspect command includes all processes that are included by the entry workflow (directly or indirectly), which has several benefits:It includes all processes that could potentially be invoked by the workflow, not just the processes that are invoked for a particular run configuration.It‚Äôs faster, as it doesn‚Äôt need to evaluate the entry workflow ‚Äì only the includes.It can be run as nextflow inspect <PIPELINE>, without specifying any parameters or config profiles.See inspect to learn more about the inspect command.When specifying a plugin, the plugin version can now be prefixed with ~ to pin the major and minor version while allowing the latest patch release. This syntax makes it possible to pin the plugin version while automatically using new patch releases.See Plugins for details.Nextflow will terminate the run if the thread pool responsible for publishing files takes too long. Previously, this timeout was reported as a warning. Now, it is reported as an error.The previous behavior can be restored with the following config setting:Nextflow now requires Java 17 or newer. See Requirements for instructions to install Java 17.The HyperQueue executor now requires HyperQueue 0.20.0 or later.The process shell section has been deprecated. See Shell for details.Nextflow will report a warning if it encounters a process shell directive that contains newlines. This warning will become an error in a future release.The -with-weblog CLI option has been deprecated. See nextflow-io/nf-weblog to learn how to use the nf-weblog plugin.New config option: aws.batch.terminateUnschedulableJobsNew config option: azure.batch.jobMaxWallClockTimeNew config option: fusion.snapshotsNew config option: google.batch.gcsfuseOptionsNew config option: google.batch.networkTagsNew config option: workflow.output.copyAttributesNew environment variable: NXF_PLUGINS_ALLOWEDNew plugin extension point: TraceObserverFactoryV2New standard library function: env()Support disk directive for Azure Batch¬© Copyright 2025, Seqera Labs, S.L.</PIPELINE></p>]]></content><author><name></name></author></entry></feed>